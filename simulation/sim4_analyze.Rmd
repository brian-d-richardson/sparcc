---
title: "Sparcc Simulation 4"
author: "Brian Richardson"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output:
  html_document:
    code_folding: hide
---

```{r message = F, warning = F}

rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(scales)
library(ggthemes)
library(kableExtra)

```

## Simulation Setup

The goal of this program is to evaluate the performance of the semiparametric efficient estimator $\widehat{\pmb{\beta}}_{sp}$ using simulations in the following setting:

* $Z \sim \textrm{Bernoulli}(0.5)$,
* $X|Z \sim \textrm{beta}(\alpha_1 + \alpha_2 Z, \alpha_3 + \alpha_4 Z)$,
* $C|Z \sim \textrm{beta}(\gamma_1 + \gamma_2 Z, \gamma_3 + \gamma_4 Z)$,
* $Y|X,Z \sim N(\beta_0 + \beta_1X + \beta_2Z, \sigma^2)$.

The assumption that $Y|X,Z$ follows a normal distribution allows us to use Gaussian quadrature to efficiently solve integrals with respect to $y$. 

In these simulations, we vary the censoring probability $q=\textrm{P}(X>C)$.

We also vary which nuisance distributions are correct by modeling $X|Z$ (or $C|Z$) as beta with estimated parameters $\pmb{\alpha}, \pmb{\gamma}$ (correct) or uniform with no parameters estimated (incorrect).

For each simulation, we generate a data set of size $n$ then compute the complete case estimator $\widehat{\pmb{\beta}}_{cc}$, the oracle estimator $\widehat{\pmb{\beta}}_{or}$, the parametric MLE $\widehat{\pmb{\beta}}_{ml}$, and the semiparametric efficient estimator $\widehat{\pmb{\beta}}_{sp}$.

```{r}

# true beta
B.true <- c(1, 10, 2, log(1))

# load simulation results from each of 10 clusters
sim.out.list <- lapply(
  X = 0:9,
  FUN = function(clust) {
    cbind(clust,
          read.csv(paste0(
            "sim4_data/v4/sd",
            clust, ".csv")))
  })

# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)

colnames(sim.out) <- gsub(".B", "", colnames(sim.out))
colnames(sim.out) <- gsub("B2", "trueB2", colnames(sim.out))

# make long data frame
sim.out.long <- sim.out %>% 
  pivot_longer(cols = starts_with(c("B", "V")),
               names_to = "method.param",
               values_to = "estimate") %>% 
  mutate(method = factor(substr(method.param, 2, 3),
                         levels = c("or", "cc", "ml", "sp")),
         name = factor(substr(method.param, 1, 1)),
         param = factor(substr(method.param, 4, 4)),
         B.true = B.true[param]) %>% 
  dplyr::select(-method.param) %>% 
  group_by(clust, n, q, method, param, name) %>% 
  mutate(id = row_number()) %>% 
  pivot_wider(names_from = name,
              values_from = estimate,
              id_cols = c(clust, n, q, method, param, B.true, id)) %>% 
  mutate(ci.lower = B - qnorm(0.975) * V,
         ci.upper = B + qnorm(0.975) * V,
         ci.cov = B.true >= ci.lower & B.true <= ci.upper)
             
```

## Simulation Results

#### Errors in Simulations

We first look at which simulation settings lead to errors.

```{r message = F}

# check for simulations with errors
sim.out.long %>% 
  filter(param == 1) %>% 
  group_by(q, n, method) %>% 
  summarize(n.error = sum(is.na(B)),
            prop.error = mean(is.na(B))) %>% 
  filter(prop.error > 0) %>% 
  kable(digits = 3) %>%
  kable_styling("striped")

```


```{r}

# extract simulation parameters
q <- unique(sim.out$q)
n <- unique(sim.out$n)
n.rep <- nrow(sim.out) /
  n_distinct(dplyr::select(sim.out, q, n, mx, mc, my, s2, trueB2, c.gamma))

# make labels for plots
method.labs <- c("Oracle",
                 "Complete Case",
                 "Parametric MLE",
                 "Semiparametric")

names(method.labs) <- c("or", "cc", "ml", "sp")

q.labs <- paste0("q = ", q)
names(q.labs) <- q

n.labs <- paste0("n = ", n)
names(n.labs) <- n

param.labs <- c("\u03B20", "\u03B21", "\u03B22", "log\u03C3\u00B2")

# colorblind friendly pallette
#pal_light <- cbbPalette <- c('#BBBBBB', '#228833', '#4477AA', '#AA3377')
#pal_dark <- cbbPalette <- c('#5d5d5d', '#114419', '#223b55', '#55193b')
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')


```

```{r}

# boxplot of simulated estimates
make.est.plot <- function(param., est_cutoff = Inf,
                          include.title = T,
                          q. = q, n. = n) {
  
  p <- sim.out.long %>% 
    filter(param == param.,
           q %in% q.,
           n %in% n.,
           abs(B - B.true) < est_cutoff) %>%  
    ggplot(aes(y = B,
               color = method,
               fill = method)) +
    geom_boxplot() +
    geom_hline(aes(yintercept = B.true),
               linetype = "dashed",
               linewidth = 0.6,
               color = pal_light[4]) +
    facet_nested(n ~ q,
                 scales = "free",
                 labeller = labeller(n = n.labs,
                                     q = q.labs)) +
    labs(y = "Parameter Estimate",
         fill = "Method",
         color = "Method") +
    theme_bw() +
    theme(axis.ticks.x = element_blank(),
          axis.text.x = element_blank(),
          axis.title.x = element_blank(),
          legend.position = "bottom") +
    scale_fill_manual(values = pal_light[c(1, 2, 3, 5, 6)],
                      labels = method.labs) +
    scale_color_manual(values = pal_dark[c(1, 2, 3, 5, 6)],
                      labels = method.labs)
  
  if (include.title) {
    p <- p +
      ggtitle(paste0("Empirical Distribution of Parameter Estimates for ",
                   param.labs[param.]),
              subtitle = paste0(n.rep, " replicates per setting"))
  }
  return(p)
}

```

#### Primary Simulation Results

The most interesting/important results are for the parameter estimates of the coefficient $\beta_1$ for $X$, and with a high censoring rate of $q = 0.8$. Below are those results, summarized with (i) a boxplot of estimates and (ii) a table with bias, variance, and MSE.

```{r message = F, fig.height = 4}

make.est.plot(param. = 1)
make.est.plot(param. = 2)
make.est.plot(param. = 3)
make.est.plot(param. = 4)

```

```{r message = F, eval = F}

ggsave("sim_plots/sim4_1_boxplot.png",
       make.est.plot(param. = 2, include.title = F),
       dpi = 300,
       height = 3,
       width = 6)

```

In the table, bias, variance, and MSE are all multiplied by a factor of 100. "Neither" means neither nuisance model is correct, "X Only" means only $X|Z$ is correct, etc.

```{r message = F}

# table summarizing for beta2 and n = 8000
tbl1 <- sim.out.long %>%
  filter(param == 2 & n == 8000) %>% 
  group_by(n, q, method) %>% 
  summarise(Bias = 100*mean(B - B.true, na.rm = T),
            ESE = 100*sd(B, na.rm = T),
            ASE = 100*mean(V, na.rm = T),
            MSE = 100*mean((B - B.true) ^ 2, na.rm = T),
            Cov = 100*mean(ci.cov))

tbl1 %>% 
  kable(digits = 1) %>%
  kable_styling("striped") %>%
  add_header_above(c(" " = 3,
                     "β1" = 5))

```

```{r message = F}

# table of all estimators x scenarios
tbl2 <- sim.out.long %>%
  group_by(n, q, param, method) %>% 
  summarise(v1_Bias = 100*mean(B - B.true, na.rm = T),
            v2_ESE = 100*sd(B, na.rm = T),
            v3_ASE = 100*mean(V, na.rm = T),
            v4_MSE = 100*mean((B - B.true) ^ 2, na.rm = T),
            v5_Cov = 100*mean(ci.cov)) %>% 
  gather(key, value, v1_Bias:v5_Cov) %>% 
  unite(Group, param, key) %>% 
  spread(Group, value)

setNames(tbl2, sub(".+_", "", names(tbl2))) %>% 
  kable(digits = 1) %>%
  kable_styling("striped") %>%
  add_header_above(c(" " = 3,
                     "β0" = 5,
                     "β1" = 5,
                     "β2" = 5,
                     "logσ²" = 5))

```


